# configs/default.yaml
# ─────────────────────
# Default configuration for rag-chunk-eval.
#
# Usage:
#   python src/evaluation/eval_metrics.py                    # uses this file
#   python src/evaluation/eval_metrics.py --config my.yaml   # uses custom file

# Reproducibility seed — controls numpy, torch, random, PYTHONHASHSEED
seed: 42

embedding:
  model_name: all-MiniLM-L6-v2
  dimension: 384

data:
  path: data/natural_questions_squad_1000.json
  min_answer_length: 8
  preprocess_html: true

evaluation:
  k_max: 5
  k_values: [1, 3, 5]
  output_dir: results

chunkers:
  FixedChunker_256:
    chunk_size: 256
    overlap: 25
  FixedChunker_512:
    chunk_size: 512
    overlap: 50
  FixedChunker_1024:
    chunk_size: 1024
    overlap: 100
  RecursiveChunker:
    max_chars: 1024
    overlap: 50
  ParagraphChunker:
    max_chars: 1024
    min_chars: 200
  SemanticDensityChunker:
    chunk_size: 1024
    min_overlap: 25
    max_overlap: 75
    density_window: 300
  StructureAwareChunker:
    chunk_size: 1024
    min_chunk_size: 200
    overlap: 50
